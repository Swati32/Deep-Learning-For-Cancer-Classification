{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils \n",
    "from SDA_layers import StackedDA \n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_dataset.csv\")\n",
    "patient = data['PatientID']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['Cancer_Type']\n",
    "X = data.drop(['Cancer_Type','PatientID'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['Cancer_Type','PatientID'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train) \n",
    "y_train = pd.DataFrame(le.transform(y_train))\n",
    "y_val = pd.DataFrame(le.transform(y_val))\n",
    "y_test = pd.DataFrame(le.transform(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation to determine alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0001    ,  0.00021544,  0.00046416,  0.001     ,  0.00215443,\n",
       "        0.00464159,  0.01      ,  0.02154435,  0.04641589,  0.1       ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.Lasso(max_iter=10000)\n",
    "alphas = np.logspace(-4, -1, 10)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [regr.set_params(alpha=alpha).fit(X_train, y_train).score(X_val, y_val) for alpha in alphas]\n",
    "best_alpha = alphas[scores.index(max(scores))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.93858158344011933,\n",
       " 0.93383503384189404,\n",
       " 0.92677959892756445,\n",
       " 0.91524314603921242,\n",
       " 0.8982021807230427,\n",
       " 0.86980129644240667,\n",
       " 0.83011119028847147,\n",
       " 0.74785111684572814,\n",
       " 0.64241631743008232,\n",
       " 0.4715145436738799]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.477211796247\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.Lasso(alpha=best_alpha, max_iter=10000)\n",
    "model = regr.fit(X_train,y_train)\n",
    "prediction = model.predict(X_test)\n",
    "y = y_test[0].as_matrix()\n",
    "print(accuracy_score(y,prediction.astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.97      0.61        36\n",
      "          1       0.74      0.39      0.51        80\n",
      "          2       0.64      0.48      0.55        29\n",
      "          3       0.10      0.33      0.15         6\n",
      "          4       0.44      0.53      0.48        32\n",
      "          5       0.45      0.60      0.51        45\n",
      "          6       0.53      0.52      0.52        52\n",
      "          7       0.44      0.22      0.29        32\n",
      "          8       0.21      0.29      0.24        21\n",
      "          9       1.00      0.30      0.46        40\n",
      "         10       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.57      0.48      0.48       373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swati\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (\"Classification Report \\n {}\".format(classification_report(y, prediction.astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Accuracy = 0\n",
    "for i in range(0,10) :\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_train) \n",
    "    y_train = pd.DataFrame(le.transform(y_train))\n",
    "    y_test = pd.DataFrame(le.transform(y_test))\n",
    "    regr = linear_model.Lasso(alpha=0.0001, max_iter=10000)\n",
    "    model = regr.fit(X_train,y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    y_test = y_test[0].as_matrix()\n",
    "    accuracy_1 = accuracy_score(y_test,prediction.astype(int))\n",
    "    Accuracy = Accuracy + accuracy_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.47184986595174261)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\",(Accuracy/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
